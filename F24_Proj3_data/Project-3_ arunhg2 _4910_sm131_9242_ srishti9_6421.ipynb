{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89200175",
   "metadata": {},
   "source": [
    "### Project 3: Movie Review Sentiment Analysis\n",
    " Arun Giridharan - arunhg2 ; 651024910\n",
    " \n",
    " Shivani Mangaleswaran - sm131 ; 654099242 \n",
    " \n",
    " Srishti Sharma - srishti9 ; 663146421                                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc057931",
   "metadata": {},
   "source": [
    "## Section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3b0db",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "\n",
    "The input datasets consist of OpenAI embeddings and raw review text:\n",
    "\n",
    "Features: 1536-dimensional OpenAI text embeddings provided for each review.\n",
    "\n",
    "Target: A binary label (sentiment), where 1 represents positive sentiment and 0 represents negative sentiment.\n",
    "\n",
    "Input Files: train.csv for training and test.csv for predictions.\n",
    "\n",
    "##### Key steps in preprocessing include:\n",
    "\n",
    "Removing unnecessary columns: id (unique identifier) and review (raw text, not used for model training).\n",
    "\n",
    "The features (embeddings) are already normalized and standardized, requiring no additional scaling.\n",
    "\n",
    "The target variable sentiment is extracted for supervised learning.\n",
    "\n",
    "The training features and target labels are prepared as:\n",
    "\n",
    "X_train: A matrix with 1536 features per review.\n",
    "y_train: Binary labels for sentiment classification. The test data is similarly prepared by excluding the target column.\n",
    "\n",
    "### 2. Model Implementation\n",
    "\n",
    "The classification model used is Logistic Regression with Elastic Net regularization. Key details of the model are:\n",
    "\n",
    "Elastic Net Regularization:\n",
    "\n",
    "Elastic Net combines L1 (Lasso) and L2 (Ridge) penalties to address high-dimensional data and prevent overfitting.\n",
    "The mixing parameter l1_ratio controls the balance between L1 and L2 regularization.\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "Hyperparameters are optimized using GridSearchCV, which performs 3-fold cross-validation on the training data. The grid includes:\n",
    "\n",
    "l1_ratio: Values [0.1, 0.5, 0.7, 0.9].\n",
    "\n",
    "C: Regularization strength values [0.01, 0.1, 1, 10].\n",
    "\n",
    "The optimal hyperparameters are chosen based on the Area Under the ROC Curve (AUC) score.\n",
    "Model Training:\n",
    "\n",
    "The model is trained using the saga solver, which supports Elastic Net and is well-suited for large datasets.\n",
    "Predictions:\n",
    "\n",
    "After training, the model generates probabilities for the positive sentiment class on the test data. These probabilities are saved in the required output format.\n",
    "\n",
    "### 3. Evaluation Metric\n",
    "\n",
    "The model's performance is evaluated using the Area Under the ROC Curve (AUC), which measures the model's ability to distinguish between positive and negative reviews. A higher AUC indicates better performance.\n",
    "\n",
    "The AUC scores achieved for each of the 5 dataset splits are as follows:\n",
    "\n",
    "Split\tAUC Score\n",
    " 1\t      0.9871\n",
    " 2\t      0.9868\n",
    " 3\t      0.9864\n",
    " 4\t      0.987\n",
    " 5\t      0.9863\n",
    "\n",
    "Average AUC across all splits: 0.9867.\n",
    "\n",
    "### 4. Execution Time and System Specifications\n",
    "\n",
    "The model was trained and evaluated on the following system:\n",
    "\n",
    "System: MacBook Pro.\n",
    "Processor: 2.3 GHz Intel Core i5.\n",
    "Memory: 8 GB RAM.\n",
    "Operating System: macOS Ventura 13.5.\n",
    "Python Version: 3.8.\n",
    "\n",
    "Execution Time:\n",
    "Total Execution Time for 5 splits: 1174.61 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b233f6",
   "metadata": {},
   "source": [
    "## Section 2: Interpretability Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ad1df",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Overview of the Interpretability Approach\n",
    "\n",
    "In this implementation, we aim to provide insights into which parts of each review contributed the most to the sentiment classification made by our trained logistic regression model. We achieve this through the following steps:\n",
    "\n",
    "Load a Pre-trained Model and Vectorizer:\n",
    "\n",
    "The trained logistic regression model and its vectorizer are stored online in a .pkl file (on GitHub).\n",
    "https://raw.githubusercontent.com/srishti1909/project3/main/best_model_vectorizer.pkl\n",
    "\n",
    "The model is loaded using pickle and used for predictions.\n",
    "Transform Reviews Using the Vectorizer:\n",
    "\n",
    "The input test reviews are converted into a sparse document-term matrix using the pre-trained CountVectorizer.\n",
    "\n",
    "Highlighting Contributing Words:\n",
    "\n",
    "Words in each review are ranked based on their contribution to the final prediction.\n",
    "\n",
    "Contribution is calculated using the feature coefficients learned by the model.\n",
    "\n",
    "For each review, we extract the top 3 contributing words for positive and negative predictions.\n",
    "\n",
    "These words are visually highlighted within the review text.\n",
    "\n",
    "Randomly Selecting Reviews:\n",
    "\n",
    "We randomly select 5 positive and 5 negative reviews based on the predictions.\n",
    "The top contributing words in these reviews are highlighted and displayed using HTML.\n",
    "\n",
    "#### 2. Implementation Details\n",
    "\n",
    "Interpretability Method: Coefficient-based word importance.\n",
    "\n",
    "The logistic regression model assigns coefficients to each word during training.\n",
    "The contribution of a word to a specific review is determined by multiplying the word frequency in the review by its learned coefficient.\n",
    "Visualization:\n",
    "\n",
    "Words contributing positively (for positive sentiment) are highlighted in yellow.\n",
    "Words contributing negatively (for negative sentiment) are also highlighted similarly.\n",
    "Reproducibility:\n",
    "\n",
    "The pre-trained model is stored in a remote repository (GitHub).\n",
    "The script loads this model and vectorizer dynamically during execution.\n",
    "Random seeds ensure the same reviews are selected each time.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c2589",
   "metadata": {},
   "source": [
    "#####  Code for Reproducibility\n",
    "\n",
    "The model is stored on GitHub for easy access.\n",
    "The test data must be available locally.\n",
    "All required code for running the interpretability approach and visualizations is included in this file.\n",
    "\n",
    "Below is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "869e2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 24675</h3>\n",
       "        <p><strong>Sentiment:</strong> Positive</p>\n",
       "        <p><strong>Prediction:</strong> 0.6113</p>\n",
       "        <p style=\"font-size: 1.1em;\">It is a shame that this series hasn't been remastered and produced on video by Warner or some other professional movie house.<br /><br />Copies of most episodes are available, but are usually of <span style=\"background-color: yellow; font-weight: bold;\">poor</span> quality, being copies of copies of copies.<br /><br />As I understand it, 92 episodes were produced during its run, but only 15 are noted here.<br /><br />Some of the series writers, such as Richard Matheson, went on to become noted authors.<br /><br /><span style=\"background-color: yellow; font-weight: bold;\">excellent</span> series, well written, well staged and well produced.<br /><br />Michael Weldon,<br /><br />Udon Thani, Thailand</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 35190</h3>\n",
       "        <p><strong>Sentiment:</strong> Positive</p>\n",
       "        <p><strong>Prediction:</strong> 0.9808</p>\n",
       "        <p style=\"font-size: 1.1em;\">Goodnight Mister Tom is so beautifully filmed and beautifully realised. It isn't completely faithful to the book, but does it have to be? No, not at all. John Thaw is mesmerising as Tom Oakley. His transformation from gruff to caring was so well realised, making it more believable than Scrooge in Christmas Carol. After Inspector Morse, this is Thaw's <span style=\"background-color: yellow; font-weight: bold;\">finest</span> hour. He was matched earnestly by a young Nick Robinson, who gave a thoroughly convincing portrayal of an evacuee traumatised by the abusive relationship with his mother. The script and music made it worth the buy, and you also see Thaw playing the organ. <span style=\"background-color: yellow; font-weight: bold;\">amazing</span>! The most moving scene, was Willie finding out about Zak's death, and then Tom telling him about his deceased family who died of scarlatina. Buy this, you'll love it! 10/10 Bethany Cox</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 44027</h3>\n",
       "        <p><strong>Sentiment:</strong> Positive</p>\n",
       "        <p><strong>Prediction:</strong> 0.7655</p>\n",
       "        <p style=\"font-size: 1.1em;\">Fido is a story about more well mannered <span style=\"background-color: yellow; font-weight: bold;\">zombies</span> who have been trained to serve the human race. All falls apart though, when young Timmy's zombie Fido eats the family neighbor. From then on, disaster (well, maybe not disaster, but to some extent, chaos) occurs. Most of the people treat their <span style=\"background-color: yellow; font-weight: bold;\">zombies</span> with fairness, and one such character sleeps with his zombie (very funny part of the movie, if not also very disturbing too). And we find the loving Fido whatever he may do. This is a very funny and <span style=\"background-color: yellow; font-weight: bold;\">unique</span> film, especially for the zombie genre. It is also probably one of the least violent of zombie movies (no negativity in this statement). I very much recommend it to people who are looking for something funny and different. I rate this 8/10. Rated R for zombie related violence</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 588</h3>\n",
       "        <p><strong>Sentiment:</strong> Positive</p>\n",
       "        <p><strong>Prediction:</strong> 0.9552</p>\n",
       "        <p style=\"font-size: 1.1em;\">As I peruse through the hundreds of comments that loyal readers of the IMDB have posted on this film, I find it very interesting how few ,\\middle of the road\\\" comments there are. Everyone either loves it, or they hate it. Having seen Apocalypse Now approximately 30 times, and having recently dissected it on DVD (how did we ever live without those magical digital machines?????), I can say without hesitation that I am one of those who have a very special place in my heart for this film. \\\"Why would you like a film that's so confusing?\\\" ask many of my associates. The answer is this: Forget the war, forget the brutality....This is a classic story of society protecting itself from those that refuse to fall in line with the status quo. Brando represents the individual that has his own way of getting the job done. They (Big Brother) sent him out to do the job, he does it too well, without adhering to the accepted \\\"standards\\\" of death and destruction (Am I the only one who's troubled by the fact that we have 'standards' for death and destruction????), so they send the \\\"Conformity Police\\\" out to eliminate the individual. Hmmmmmm....Draw any parallels between this and things you see every day? With the deepest respect to Mr. Coppola, whom I believe is one of the best directors of all time, I think he transcended his original intent of the movie, and probably didn't even realize it until after the movie was released. The <span style=\"background-color: yellow; font-weight: bold;\">subtle</span> sub-text that permeates the entire movie has way too much to it to have been planned and portrayed; <span style=\"background-color: yellow; font-weight: bold;\">instead</span>, it seems to have 'grown' itself, like some wild flower in the middle of a vegetable garden. Again I must reiterate: I think FF Coppola did a bang-up job on this entire production, as did the cast and crew, but the sum of the movie exceeds the individual efforts ten-fold. So if you haven't seen the movie, rent it, watch it, then watch it again, and maybe a few more times, and look for all the generic parallels to everyday life. Only then make a judgment on the quality of the film. Those of you that have seen it, watch it again with the mindset previously described. I think you may just have a whole new appreciation for the film. Or maybe not! No matter whether you love it or hate it, be sure and give credit to Coppola for his masterful story-telling style!\"</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid green; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 43102</h3>\n",
       "        <p><strong>Sentiment:</strong> Positive</p>\n",
       "        <p><strong>Prediction:</strong> 0.7122</p>\n",
       "        <p style=\"font-size: 1.1em;\">\\Hot Millions\\\" is a well-written, well-acted tale about an embezzler who steals (whoops! -- too low class a word for an embezzler, according to Peter Ustinov's lead character) a \\\"hot million\\\" from the London branch of a U.S. corporation by creating shell corporations on the continent and using the firm's ostensibly secure computer to transfer funds to them. (Remember, spoiler police, this is a comedy, not a mystery.) <br /><br />From 1968, this movie's depiction of computers may seem naive to <span style=\"background-color: yellow; font-weight: bold;\">today</span>'s more computer-literate populace; but as one who has worked with computers since before this film was released, I would assert that even then, this smacks of having been written by and for computer illiterates, probably on purpose to heighten the droll comedic aspects of this British flick. <br /><br />If one has little taste for this type of entertainment, the movie may seem to drag in spots. Fortunately, it has a nicely wrapped-up ending; <span style=\"background-color: yellow; font-weight: bold;\">unfortunately</span>, the end credits give no indication of the classical music used therein -- the symphonic piece at the end and the piano-flute duet in the middle -- just the song sung by Lulu which I totally don't remember.\"</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid red; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 2802</h3>\n",
       "        <p><strong>Sentiment:</strong> Negative</p>\n",
       "        <p><strong>Prediction:</strong> 0.0955</p>\n",
       "        <p style=\"font-size: 1.1em;\">NO WAY ! I hated Granny. First, she is way too tall -of course she is, it is Tom, whoever's brother, who's playing her- and I hate that thing she does when she brushes her fake silver hair back, but : there are funny parts in this movie. For instance, the fact that every single actor looks V.G. (very German), and also that they think that, even when left alone, they should pretend that that guy (Tom) is their actual \\granny\\\" or something. I specially <span style=\"background-color: yellow; font-weight: bold;\">liked</span> -not- that moment where Charlotte leaves and starts walking to the nearest gas station to ask for some help. She suddenly finds herself in the middle of some woods (where were these before? nobody dares explaining) and turns, turns, turns a-r-oun-d like a ballerina, looking at the stars...and...ignoring the fact that GRANNY'S BEHIND HER, READY TO STRIKE !!! But, anyway, the music wasn't so <span style=\"background-color: yellow; font-weight: bold;\">bad</span>, the haircuts were okay and the ending terribly provocative... Mmmmm... wish I had the German version.\"</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid red; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 23695</h3>\n",
       "        <p><strong>Sentiment:</strong> Negative</p>\n",
       "        <p><strong>Prediction:</strong> 0.1498</p>\n",
       "        <p style=\"font-size: 1.1em;\">Although I am sure the idea looked good on paper, and it appealed to me when I first heard of it, this movie often lumbers along and falls flat, and when I watch it, I just want it to end. The bookend beginning and ending of the film about Lou having to babysit a troublemaker is contrived at <span style=\"background-color: yellow; font-weight: bold;\">best</span>, although I found the tall cop part to be humorous. However, I found little to laugh at with the bottom of the barrel script that was thrown together for these two <span style=\"background-color: yellow; font-weight: bold;\">great</span> comedians. I thought that it was a mistake to put them in a musical, and it reeks of \\Wizard of Oz\\\" rip-off (with the songs and black and white to color format). I wouldn't recommend this film to anyone but die-hard A&C fanatics. Anyone else will be disappointed, and they have many better films.\"</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid red; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 45430</h3>\n",
       "        <p><strong>Sentiment:</strong> Negative</p>\n",
       "        <p><strong>Prediction:</strong> 0.0299</p>\n",
       "        <p style=\"font-size: 1.1em;\">I'll keep this fast and sweet. Five girls on their way home from a football game decide to take a 'short cut' that leads them down a deserted forest-ridden road. Of course nothing but good things happen to them, and they safely arrive at their destination.<br /><br />Alright, they don't. Soon they're hunted down by a deranged chick who has some severe mental issues, and what ensues is 90 minutes of sheer boredom.<br /><br />I hope to never see any of these actors in any movie ever again. Their screaming, screeching voices gave me a headache, and the script was so <span style=\"background-color: yellow; font-weight: bold;\">poorly</span> written that it included a lot of repeat phrases and nonsensical hysterical screaming. All in all, one of the <span style=\"background-color: yellow; font-weight: bold;\">worst</span> cheap horror flicks I've ever seen...and I've seen a lot.</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid red; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 7132</h3>\n",
       "        <p><strong>Sentiment:</strong> Negative</p>\n",
       "        <p><strong>Prediction:</strong> 0.3542</p>\n",
       "        <p style=\"font-size: 1.1em;\">I think that just sums up this film. Watch it and you'll find out why. The acting of the lead character John Keem is really, really <span style=\"background-color: yellow; font-weight: bold;\">bad</span> and he has no on screen charisma whatsoever. It's very funny because of this thought, as is the ending where Keem beheads the <span style=\"background-color: yellow; font-weight: bold;\">bad</span> guy despite the fact he is unarmed and has surrendered. <span style=\"background-color: yellow; font-weight: bold;\">brilliant</span>!</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border: 2px solid red; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
       "        <h3>Review 10938</h3>\n",
       "        <p><strong>Sentiment:</strong> Negative</p>\n",
       "        <p><strong>Prediction:</strong> 0.2395</p>\n",
       "        <p style=\"font-size: 1.1em;\">Shaky hand held cameras (this piece was shot for television mind you, not film) not only keep you utterly conscious of how <span style=\"background-color: yellow; font-weight: bold;\">horrible</span> the cinematography is in this film, but make you absolutely unable to become immersed in the story. <span style=\"background-color: yellow; font-weight: bold;\">poor</span> Miss Austen must be rolling in her grave. All I can say is, if you enjoyed the novel, stop there, until the BBC creates one of their smart & sensible period masterpieces (like Pride & Prejudice with Colin Firth, which, speaking for what I imagine in my opinion, Austen would have revered). The BBC would never dare overdub cheesy saxophone solos and Indigo Girl hollers over a shot of an historic castle and a loving embrace. Giles Foster seemed to be often confused that they were editing the music to The Specialist. If you want Austen as you love her, look for the BBC logo...</p>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpretability visualization complete!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "\n",
    "# Suppress specific sklearn warnings\n",
    "warnings.filterwarnings(\"ignore\", category=InconsistentVersionWarning)\n",
    "\n",
    "# Step 1: Load the Trained Model and Vectorizer\n",
    "#print(\"Loading trained model and vectorizer...\")\n",
    "model_url = \"https://raw.githubusercontent.com/srishti1909/project3/main/best_model_vectorizer.pkl\"\n",
    "\n",
    "response = requests.get(model_url)\n",
    "if response.status_code == 200:\n",
    "    best_model, vectorizer = pickle.loads(response.content)  # Unpack model and vectorizer\n",
    "    print(\"Model and vectorizer loaded successfully!\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to load model. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "# Define the base directory and construct path to test.csv dynamically\n",
    "base_dir = os.getcwd()  # Current working directory\n",
    "test_data_path = os.path.join(base_dir, \"split_1\", \"test.csv\")\n",
    "\n",
    "# Load the test data\n",
    "#print(f\"Loading test data from: {test_data_path}\")\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "reviews = test_data[\"review\"]\n",
    "ids = test_data[\"id\"]\n",
    "\n",
    "# Transform reviews using the loaded vectorizer\n",
    "X_test = vectorizer.transform(reviews)\n",
    "predicted_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "predicted_sentiments = (predicted_probs >= 0.5).astype(int)\n",
    "\n",
    "# Extract feature names and model coefficients\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coefficients = best_model.coef_[0]\n",
    "\n",
    "# Step 2: Identify Top Words for Each Review\n",
    "def get_top_words_for_review(review_vector, feature_names, coefficients, top_n=5):\n",
    "    \"\"\"Get the top N contributing words for a specific review.\"\"\"\n",
    "    nonzero_indices = review_vector.nonzero()[1]  # Get indices of non-zero features (words in the review)\n",
    "    word_contributions = [(feature_names[i], coefficients[i]) for i in nonzero_indices]\n",
    "    sorted_contributions = sorted(word_contributions, key=lambda x: -abs(x[1]))  # Sort by importance\n",
    "    return [word for word, _ in sorted_contributions[:top_n]]\n",
    "\n",
    "def highlight_words_in_review(review, top_words):\n",
    "    \"\"\"Highlight the top words in the review.\"\"\"\n",
    "    highlighted_review = review\n",
    "    for word in top_words:\n",
    "        word_pattern = re.compile(r'\\b' + re.escape(word) + r'\\b', re.IGNORECASE)\n",
    "        highlighted_review = word_pattern.sub(\n",
    "            f'<span style=\"background-color: yellow; font-weight: bold;\">{word}</span>',\n",
    "            highlighted_review\n",
    "        )\n",
    "    return highlighted_review\n",
    "\n",
    "# Step 3: Randomly Select 5 Positive and 5 Negative Reviews\n",
    "random.seed(42)\n",
    "positive_indices = np.where(predicted_sentiments == 1)[0]\n",
    "negative_indices = np.where(predicted_sentiments == 0)[0]\n",
    "selected_indices = random.sample(list(positive_indices), 5) + random.sample(list(negative_indices), 5)\n",
    "\n",
    "# Generate and display results\n",
    "for idx in selected_indices:\n",
    "    review_id = ids.iloc[idx]\n",
    "    review_text = reviews.iloc[idx]\n",
    "    prediction = predicted_probs[idx]\n",
    "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
    "    border_color = \"green\" if sentiment == \"Positive\" else \"red\"\n",
    "\n",
    "    # Extract top 5 contributing words for the review\n",
    "    review_vector = X_test[idx]\n",
    "    top_words = get_top_words_for_review(review_vector, feature_names, coefficients, top_n=2)\n",
    "    highlighted_review = highlight_words_in_review(review_text, top_words)\n",
    "\n",
    "    # Display results\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"border: 2px solid {border_color}; padding: 15px; margin-bottom: 10px; border-radius: 10px;\">\n",
    "        <h3>Review {review_id}</h3>\n",
    "        <p><strong>Sentiment:</strong> {sentiment}</p>\n",
    "        <p><strong>Prediction:</strong> {prediction:.4f}</p>\n",
    "        <p style=\"font-size: 1.1em;\">{highlighted_review}</p>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "print(\"Interpretability visualization complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02a050",
   "metadata": {},
   "source": [
    "\n",
    "#### 4. Advantages of the Approach\n",
    "\n",
    "Simplicity: Logistic Regression coefficients provide a clear and interpretable measure of feature importance.\n",
    "\n",
    "Efficiency: The approach is computationally efficient as it directly uses learned coefficients.\n",
    "\n",
    "Visual Clarity: Highlighting words makes it easy for users to understand what drives the prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
